{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\AppData\\Local\\Temp\\ipykernel_37576\\2203143384.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['bmi'].fillna(data['bmi'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset (replace 'healthcare-dataset-stroke-data.csv' with your file path)\n",
    "data = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "# Drop 'id' column if present\n",
    "if 'id' in data.columns:\n",
    "    data = data.drop('id', axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "data['bmi'].fillna(data['bmi'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "categorical_cols = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "for col in categorical_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Create derived features\n",
    "data['age_glucose'] = data['age'] * data['avg_glucose_level']\n",
    "data['comorbidity'] = data['hypertension'] | data['heart_disease']\n",
    "data['age_group'] = pd.cut(data['age'], bins=[0, 40, 60, 120], labels=[0, 1, 2], include_lowest=True)\n",
    "data['age_group'] = data['age_group'].astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = data[['age', 'gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type',\n",
    "          'avg_glucose_level', 'bmi', 'smoking_status', 'age_glucose', 'comorbidity', 'age_group']]\n",
    "y = data['stroke']\n",
    "\n",
    "# Split the data (before balancing to avoid data leakage)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after ROS: stroke\n",
      "0    3889\n",
      "1    3889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply Random Over Sampling to the training set\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after ROS\n",
    "print(\"Class distribution after ROS:\", pd.Series(y_train_ros).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       972\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.94      1022\n",
      "   macro avg       0.48      0.49      0.48      1022\n",
      "weighted avg       0.90      0.94      0.92      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRandom Forest Test Set Performance:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Logistic regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86       972\n",
      "           1       0.14      0.80      0.25        50\n",
      "\n",
      "    accuracy                           0.76      1022\n",
      "   macro avg       0.57      0.78      0.55      1022\n",
      "weighted avg       0.95      0.76      0.83      1022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shubham\\Documents\\ds_mini\\mini\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize Logistic Regression with class weights\n",
    "lr_model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predict on the test set\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nLogistic Regression Test Set Performance:\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86       972\n",
      "           1       0.14      0.80      0.25        50\n",
      "\n",
      "    accuracy                           0.76      1022\n",
      "   macro avg       0.57      0.78      0.55      1022\n",
      "weighted avg       0.95      0.76      0.83      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       972\n",
      "           1       0.20      0.26      0.23        50\n",
      "\n",
      "    accuracy                           0.91      1022\n",
      "   macro avg       0.58      0.60      0.59      1022\n",
      "weighted avg       0.92      0.91      0.92      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# Calculate scale_pos_weight (ratio of negative to positive samples in the original training set)\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Initialize XGBoost with scale_pos_weight\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predict on the test set\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nXGBoost Test Set Performance:\")\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance metrics saved to 'model_performance_metrics.csv'\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Create a dictionary with the metrics\n",
    "# metrics_data = {\n",
    "#     'Model': ['Random Forest', 'Logistic Regression', 'XGBoost'],\n",
    "#     'F1-Score (Class 1)': [0.00, 0.25, 0.23],\n",
    "#     'Recall (Class 1)': [0.00, 0.80, 0.26],\n",
    "#     'Precision (Class 1)': [0.00, 0.14, 0.20],\n",
    "#     'Weighted F1-Score': [0.92, 0.83, 0.92],\n",
    "#     'Accuracy': [0.94, 0.76, 0.91]\n",
    "# }\n",
    "\n",
    "# # Convert to a DataFrame and save to CSV\n",
    "# metrics_df = pd.DataFrame(metrics_data)\n",
    "# metrics_df.to_csv('model_performance_metrics.csv', index=False)\n",
    "# print(\"Model performance metrics saved to 'model_performance_metrics.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved as 'random_forest_model.pkl', 'logistic_regression_model.pkl', and 'xgboost_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Save the Random Forest model\n",
    "# joblib.dump(rf_model, 'models/random_forest_model.pkl')\n",
    "\n",
    "# # Save the Logistic Regression model (with scaled data, if you re-trained it)\n",
    "# joblib.dump(lr_model, 'models/logistic_regression_model.pkl')\n",
    "\n",
    "# # Save the XGBoost model\n",
    "# joblib.dump(xgb_model, 'models/xgboost_model.pkl')\n",
    "\n",
    "# print(\"Models saved as 'random_forest_model.pkl', 'logistic_regression_model.pkl', and 'xgboost_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
